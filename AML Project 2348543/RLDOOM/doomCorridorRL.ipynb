{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5363a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27881e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gymnasium import Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c27a8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = DoomGame()\n",
    "game.load_config('/Users/raghavsuri/Desktop/RLDOOM/Github/ViZDoom-master/scenarios/deadly_corridor.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20f45f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.,   0.,   0.,  -1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = game.get_state()\n",
    "state.game_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c5ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set of possible actions in environment\n",
    "actions = np.identity(7, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c991fcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e49fe42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b3d964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899590ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    game.make_action(random.choice(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0992934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = game.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f26f28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.game_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f188c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d3ff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  -7.083099365234375\n",
      "reward:  -7.8697509765625\n",
      "reward:  -0.6162109375\n",
      "reward:  0.82183837890625\n",
      "reward:  -1.2011566162109375\n",
      "reward:  -0.0289306640625\n",
      "reward:  0.0\n",
      "reward:  -0.022430419921875\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  7.0300750732421875\n",
      "reward:  9.471878051757812\n",
      "reward:  6.9340667724609375\n",
      "reward:  -2.3532867431640625\n",
      "reward:  -4.2180328369140625\n",
      "reward:  -0.9290008544921875\n",
      "reward:  -2.4835662841796875\n",
      "reward:  -6.0238037109375\n",
      "reward:  -5.8045806884765625\n",
      "reward:  -1.599578857421875\n",
      "reward:  1.85662841796875\n",
      "reward:  9.071441650390625\n",
      "reward:  9.712890625\n",
      "reward:  5.5130767822265625\n",
      "reward:  3.1733245849609375\n",
      "reward:  2.126007080078125\n",
      "reward:  3.8274383544921875\n",
      "reward:  2.939788818359375\n",
      "reward:  0.89056396484375\n",
      "reward:  4.528594970703125\n",
      "reward:  0.4035797119140625\n",
      "reward:  -6.3399658203125\n",
      "reward:  -6.3393707275390625\n",
      "reward:  0.30615234375\n",
      "reward:  -0.826263427734375\n",
      "reward:  0.54620361328125\n",
      "reward:  6.35906982421875\n",
      "reward:  2.423797607421875\n",
      "reward:  -0.403289794921875\n",
      "reward:  -0.2019195556640625\n",
      "reward:  4.517791748046875\n",
      "reward:  5.40069580078125\n",
      "reward:  3.642730712890625\n",
      "reward:  -3.1870269775390625\n",
      "reward:  -10.570083618164062\n",
      "reward:  -10.035003662109375\n",
      "reward:  -3.7820892333984375\n",
      "reward:  -2.55120849609375\n",
      "reward:  -1.720916748046875\n",
      "reward:  -1.1609039306640625\n",
      "reward:  -6.839569091796875\n",
      "reward:  -1.7376861572265625\n",
      "reward:  2.0081939697265625\n",
      "reward:  1.354461669921875\n",
      "reward:  0.9135284423828125\n",
      "reward:  6.8050384521484375\n",
      "reward:  7.840087890625\n",
      "reward:  11.0772705078125\n",
      "reward:  10.511764526367188\n",
      "reward:  7.0902557373046875\n",
      "reward:  4.7824249267578125\n",
      "reward:  -1.6563873291015625\n",
      "reward:  -3.2774810791015625\n",
      "reward:  -1.6536407470703125\n",
      "reward:  -2.9052886962890625\n",
      "reward:  1.850128173828125\n",
      "reward:  8.056625366210938\n",
      "reward:  7.4132843017578125\n",
      "reward:  -0.302032470703125\n",
      "reward:  -2.9882354736328125\n",
      "reward:  -6.4947052001953125\n",
      "reward:  -11.2120361328125\n",
      "reward:  -9.3170166015625\n",
      "reward:  -3.12396240234375\n",
      "reward:  -2.034423828125\n",
      "reward:  -1.372406005859375\n",
      "reward:  2.4792633056640625\n",
      "reward:  -2.5581817626953125\n",
      "reward:  -4.731109619140625\n",
      "reward:  -3.1912994384765625\n",
      "reward:  -2.1526641845703125\n",
      "reward:  -1.4521331787109375\n",
      "reward:  -101.44401550292969\n",
      "Result:  -94.11578369140625\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  -6.9005279541015625\n",
      "reward:  -8.278350830078125\n",
      "reward:  -0.2597503662109375\n",
      "reward:  0.609222412109375\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  -1.14727783203125\n",
      "reward:  -0.0226287841796875\n",
      "reward:  0.2042236328125\n",
      "reward:  7.355194091796875\n",
      "reward:  8.49072265625\n",
      "reward:  -1.490692138671875\n",
      "reward:  -14.425018310546875\n",
      "reward:  7.110260009765625\n",
      "reward:  8.529800415039062\n",
      "reward:  5.7534027099609375\n",
      "reward:  3.8806610107421875\n",
      "reward:  9.700347900390625\n",
      "reward:  10.89007568359375\n",
      "reward:  5.0254364013671875\n",
      "reward:  2.7320556640625\n",
      "reward:  -5.90618896484375\n",
      "reward:  -6.0870513916015625\n",
      "reward:  -4.1058807373046875\n",
      "reward:  -2.769561767578125\n",
      "reward:  -1.8681488037109375\n",
      "reward:  -0.5447998046875\n",
      "reward:  7.063385009765625\n",
      "reward:  8.483779907226562\n",
      "reward:  12.805252075195312\n",
      "reward:  12.35675048828125\n",
      "reward:  8.334747314453125\n",
      "reward:  3.0463714599609375\n",
      "reward:  -0.0605010986328125\n",
      "reward:  1.108184814453125\n",
      "reward:  0.0834197998046875\n",
      "reward:  0.649658203125\n",
      "reward:  2.3221588134765625\n",
      "reward:  7.89471435546875\n",
      "reward:  2.004425048828125\n",
      "reward:  -0.76226806640625\n",
      "reward:  0.3735809326171875\n",
      "reward:  6.950103759765625\n",
      "reward:  8.08636474609375\n",
      "reward:  -1.6457061767578125\n",
      "reward:  -2.9368438720703125\n",
      "reward:  -0.57611083984375\n",
      "reward:  -0.38873291015625\n",
      "reward:  -7.372711181640625\n",
      "reward:  -1.5967864990234375\n",
      "reward:  1.9205474853515625\n",
      "reward:  -1.407958984375\n",
      "reward:  -2.0956878662109375\n",
      "reward:  -1.1157379150390625\n",
      "reward:  6.659820556640625\n",
      "reward:  8.211563110351562\n",
      "reward:  5.5387725830078125\n",
      "reward:  3.735870361328125\n",
      "reward:  2.5197906494140625\n",
      "reward:  -5.414215087890625\n",
      "reward:  -0.27398681640625\n",
      "reward:  3.5508575439453125\n",
      "reward:  -4.6645355224609375\n",
      "reward:  -6.8536529541015625\n",
      "reward:  -99.26411437988281\n",
      "Result:  -6.25390625\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.8306884765625\n",
      "reward:  1.516021728515625\n",
      "reward:  0.3022918701171875\n",
      "reward:  -7.292724609375\n",
      "reward:  -8.626800537109375\n",
      "reward:  -2.6820220947265625\n",
      "reward:  -0.0255889892578125\n",
      "reward:  0.0\n",
      "reward:  -0.014129638671875\n",
      "reward:  2.256072998046875\n",
      "reward:  -2.2019805908203125\n",
      "reward:  6.712310791015625\n",
      "reward:  7.2257080078125\n",
      "reward:  -0.9959259033203125\n",
      "reward:  -5.722412109375\n",
      "reward:  -7.2208404541015625\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  6.636871337890625\n",
      "reward:  10.414718627929688\n",
      "reward:  8.312881469726562\n",
      "reward:  5.6070404052734375\n",
      "reward:  -3.3285369873046875\n",
      "reward:  -5.73736572265625\n",
      "reward:  5.758575439453125\n",
      "reward:  14.728302001953125\n",
      "reward:  12.736282348632812\n",
      "reward:  7.495452880859375\n",
      "reward:  -2.1620025634765625\n",
      "reward:  -5.3966064453125\n",
      "reward:  -2.7811737060546875\n",
      "reward:  -1.1281585693359375\n",
      "reward:  -7.0311279296875\n",
      "reward:  -7.65771484375\n",
      "reward:  -5.1653594970703125\n",
      "reward:  -3.4842376708984375\n",
      "reward:  -9.0499267578125\n",
      "reward:  -13.158889770507812\n",
      "reward:  -4.870758056640625\n",
      "reward:  -0.7918701171875\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  6.992431640625\n",
      "reward:  8.388442993164062\n",
      "reward:  -1.1218414306640625\n",
      "reward:  -4.3171844482421875\n",
      "reward:  3.8676300048828125\n",
      "reward:  6.1689910888671875\n",
      "reward:  7.0047760009765625\n",
      "reward:  7.0234375\n",
      "reward:  -4.9141845703125\n",
      "reward:  -3.448394775390625\n",
      "reward:  -0.796539306640625\n",
      "reward:  -0.5373992919921875\n",
      "reward:  -0.36260986328125\n",
      "reward:  -6.00323486328125\n",
      "reward:  -0.940155029296875\n",
      "reward:  -1.9808349609375\n",
      "reward:  -6.1537017822265625\n",
      "reward:  -2.4497528076171875\n",
      "reward:  0.179779052734375\n",
      "reward:  -6.053558349609375\n",
      "reward:  1.7163848876953125\n",
      "reward:  6.893341064453125\n",
      "reward:  4.50164794921875\n",
      "reward:  0.192352294921875\n",
      "reward:  1.48004150390625\n",
      "reward:  -0.3523406982421875\n",
      "reward:  -1.7312469482421875\n",
      "reward:  -1.1678619384765625\n",
      "reward:  2.794586181640625\n",
      "reward:  3.7661895751953125\n",
      "reward:  2.5402679443359375\n",
      "reward:  -5.2357635498046875\n",
      "reward:  -109.94100952148438\n",
      "Result:  -109.99024963378906\n",
      "reward:  0.0\n",
      "reward:  0.78125\n",
      "reward:  9.571823120117188\n",
      "reward:  3.07818603515625\n",
      "reward:  -1.659515380859375\n",
      "reward:  -1.11944580078125\n",
      "reward:  6.3586273193359375\n",
      "reward:  4.4410400390625\n",
      "reward:  -5.02777099609375\n",
      "reward:  -0.013336181640625\n",
      "reward:  3.72662353515625\n",
      "reward:  1.4925079345703125\n",
      "reward:  -2.6668243408203125\n",
      "reward:  -0.8589019775390625\n",
      "reward:  -1.4154510498046875\n",
      "reward:  5.15081787109375\n",
      "reward:  6.704498291015625\n",
      "reward:  4.522216796875\n",
      "reward:  3.05023193359375\n",
      "reward:  -5.0529632568359375\n",
      "reward:  -7.1423187255859375\n",
      "reward:  -4.8177337646484375\n",
      "reward:  -9.674423217773438\n",
      "reward:  -11.04510498046875\n",
      "reward:  -1.749237060546875\n",
      "reward:  0.778106689453125\n",
      "reward:  -2.193115234375\n",
      "reward:  -7.8192901611328125\n",
      "reward:  -3.3275146484375\n",
      "reward:  -0.0715789794921875\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  2.6364898681640625\n",
      "reward:  -2.5810089111328125\n",
      "reward:  -0.0478057861328125\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  5.115234375\n",
      "reward:  6.2020721435546875\n",
      "reward:  4.18328857421875\n",
      "reward:  2.8216094970703125\n",
      "reward:  1.90313720703125\n",
      "reward:  -2.562408447265625\n",
      "reward:  -9.519851684570312\n",
      "reward:  -8.088699340820312\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  -0.0545501708984375\n",
      "reward:  6.3544158935546875\n",
      "reward:  0.51068115234375\n",
      "reward:  4.195465087890625\n",
      "reward:  8.523345947265625\n",
      "reward:  4.5139007568359375\n",
      "reward:  1.6787872314453125\n",
      "reward:  1.132293701171875\n",
      "reward:  -2.0803070068359375\n",
      "reward:  -2.1265411376953125\n",
      "reward:  -1.434478759765625\n",
      "reward:  -0.96771240234375\n",
      "reward:  -0.6528472900390625\n",
      "reward:  -4.620208740234375\n",
      "reward:  -5.24127197265625\n",
      "reward:  -3.535430908203125\n",
      "reward:  -2.384796142578125\n",
      "reward:  -1.502593994140625\n",
      "reward:  1.6760711669921875\n",
      "reward:  -3.9915771484375\n",
      "reward:  2.905914306640625\n",
      "reward:  -0.2726593017578125\n",
      "reward:  2.4510955810546875\n",
      "reward:  4.342926025390625\n",
      "reward:  2.929290771484375\n",
      "reward:  -4.1738128662109375\n",
      "reward:  -6.5345458984375\n",
      "reward:  0.0\n",
      "reward:  0.98822021484375\n",
      "reward:  4.0177459716796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:  2.7099456787109375\n",
      "reward:  7.8840484619140625\n",
      "reward:  12.076187133789062\n",
      "reward:  16.080673217773438\n",
      "reward:  17.60491943359375\n",
      "reward:  19.8099365234375\n",
      "reward:  13.342315673828125\n",
      "reward:  8.12628173828125\n",
      "reward:  -96.59114074707031\n",
      "Result:  -8.246551513671875\n",
      "reward:  0.0\n",
      "reward:  0.78125\n",
      "reward:  2.4580535888671875\n",
      "reward:  1.657928466796875\n",
      "reward:  0.490509033203125\n",
      "reward:  7.0840301513671875\n",
      "reward:  7.1193389892578125\n",
      "reward:  4.4983673095703125\n",
      "reward:  5.8780059814453125\n",
      "reward:  5.4581146240234375\n",
      "reward:  3.6814422607421875\n",
      "reward:  0.2218475341796875\n",
      "reward:  -7.7486572265625\n",
      "reward:  -8.214736938476562\n",
      "reward:  -8.031723022460938\n",
      "reward:  -6.605133056640625\n",
      "reward:  -4.4553070068359375\n",
      "reward:  -3.0052642822265625\n",
      "reward:  -3.4826202392578125\n",
      "reward:  -3.113494873046875\n",
      "reward:  -2.7433929443359375\n",
      "reward:  -7.8303375244140625\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.6275482177734375\n",
      "reward:  7.835662841796875\n",
      "reward:  1.9216461181640625\n",
      "reward:  -1.7871246337890625\n",
      "reward:  -6.585968017578125\n",
      "reward:  -0.00274658203125\n",
      "reward:  -2.007171630859375\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  7.1137542724609375\n",
      "reward:  3.5246124267578125\n",
      "reward:  -4.6822662353515625\n",
      "reward:  -6.0002288818359375\n",
      "reward:  0.0\n",
      "reward:  -0.032257080078125\n",
      "reward:  0.0\n",
      "reward:  -0.0179901123046875\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  2.4576568603515625\n",
      "reward:  2.9482269287109375\n",
      "reward:  -4.9107208251953125\n",
      "reward:  -0.4771881103515625\n",
      "reward:  0.0\n",
      "reward:  -0.0016326904296875\n",
      "reward:  5.1303253173828125\n",
      "reward:  4.0977935791015625\n",
      "reward:  1.47320556640625\n",
      "reward:  0.993560791015625\n",
      "reward:  0.670074462890625\n",
      "reward:  0.3516845703125\n",
      "reward:  1.861602783203125\n",
      "reward:  0.371429443359375\n",
      "reward:  1.1343994140625\n",
      "reward:  1.7426910400390625\n",
      "reward:  1.17535400390625\n",
      "reward:  -1.85943603515625\n",
      "reward:  3.906036376953125\n",
      "reward:  6.07586669921875\n",
      "reward:  7.07080078125\n",
      "reward:  10.584869384765625\n",
      "reward:  3.756195068359375\n",
      "reward:  -6.86932373046875\n",
      "reward:  -7.8711395263671875\n",
      "reward:  -5.3093109130859375\n",
      "reward:  -3.581329345703125\n",
      "reward:  -6.3480224609375\n",
      "reward:  -6.3469390869140625\n",
      "reward:  -7.5005035400390625\n",
      "reward:  -4.682037353515625\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  4.1016387939453125\n",
      "reward:  4.92047119140625\n",
      "reward:  -1.7993011474609375\n",
      "reward:  1.2165069580078125\n",
      "reward:  8.62615966796875\n",
      "reward:  13.245330810546875\n",
      "reward:  16.162109375\n",
      "reward:  10.490341186523438\n",
      "reward:  -3.8827056884765625\n",
      "reward:  -8.8748779296875\n",
      "reward:  -8.140380859375\n",
      "reward:  -11.175384521484375\n",
      "reward:  0.6787261962890625\n",
      "reward:  4.74786376953125\n",
      "reward:  -1.9157257080078125\n",
      "reward:  -3.9800262451171875\n",
      "reward:  -7.423980712890625\n",
      "reward:  -7.4964447021484375\n",
      "reward:  0.6277923583984375\n",
      "reward:  -2.4882049560546875\n",
      "reward:  -7.59051513671875\n",
      "reward:  0.0\n",
      "reward:  4.7392425537109375\n",
      "reward:  5.5915985107421875\n",
      "reward:  -1.63348388671875\n",
      "reward:  -8.707366943359375\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  5.4347381591796875\n",
      "reward:  11.95452880859375\n",
      "reward:  7.40374755859375\n",
      "reward:  2.2413787841796875\n",
      "reward:  6.317138671875\n",
      "reward:  6.78436279296875\n",
      "reward:  -0.2294464111328125\n",
      "reward:  -2.6784210205078125\n",
      "reward:  -7.2181854248046875\n",
      "reward:  -2.56121826171875\n",
      "reward:  -3.596771240234375\n",
      "reward:  -0.32318115234375\n",
      "reward:  -2.3212738037109375\n",
      "reward:  -3.8916015625\n",
      "reward:  -2.62506103515625\n",
      "reward:  -6.802642822265625\n",
      "reward:  -2.272552490234375\n",
      "reward:  1.1424407958984375\n",
      "reward:  5.24041748046875\n",
      "reward:  5.806671142578125\n",
      "reward:  -1.613525390625\n",
      "reward:  -3.8726348876953125\n",
      "reward:  -2.6123046875\n",
      "reward:  -1.7621612548828125\n",
      "reward:  -5.35406494140625\n",
      "reward:  -2.6610870361328125\n",
      "reward:  4.428680419921875\n",
      "reward:  5.312835693359375\n",
      "reward:  -1.4483489990234375\n",
      "reward:  -8.2275390625\n",
      "reward:  -0.0669097900390625\n",
      "reward:  4.8053741455078125\n",
      "reward:  5.0676422119140625\n",
      "reward:  -0.524078369140625\n",
      "reward:  -2.877166748046875\n",
      "reward:  -6.418792724609375\n",
      "reward:  -0.0529937744140625\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  5.0318145751953125\n",
      "reward:  10.841781616210938\n",
      "reward:  14.868255615234375\n",
      "reward:  7.6393585205078125\n",
      "reward:  2.510345458984375\n",
      "reward:  5.996185302734375\n",
      "reward:  5.0542449951171875\n",
      "reward:  -1.0081787109375\n",
      "reward:  2.4026641845703125\n",
      "reward:  -1.112091064453125\n",
      "reward:  -8.020858764648438\n",
      "reward:  -9.45916748046875\n",
      "reward:  -6.138671875\n",
      "reward:  -9.914169311523438\n",
      "reward:  -12.156967163085938\n",
      "reward:  -6.477569580078125\n",
      "reward:  -0.0005035400390625\n",
      "reward:  -0.0324249267578125\n",
      "reward:  -0.002166748046875\n",
      "reward:  -0.0240020751953125\n",
      "reward:  4.428680419921875\n",
      "reward:  5.312835693359375\n",
      "reward:  3.5835113525390625\n",
      "reward:  2.4170379638671875\n",
      "reward:  1.630218505859375\n",
      "reward:  1.0994873046875\n",
      "reward:  0.7415008544921875\n",
      "reward:  4.8030548095703125\n",
      "reward:  5.49932861328125\n",
      "reward:  8.012283325195312\n",
      "reward:  7.26165771484375\n",
      "reward:  0.59100341796875\n",
      "reward:  -7.2961578369140625\n",
      "reward:  -12.078720092773438\n",
      "reward:  -4.972320556640625\n",
      "reward:  -0.1395111083984375\n",
      "reward:  -3.9324493408203125\n",
      "reward:  -10.115097045898438\n",
      "reward:  -6.789947509765625\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  -0.02703857421875\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  6.4973602294921875\n",
      "reward:  14.291976928710938\n",
      "reward:  6.5545654296875\n",
      "reward:  1.0089263916015625\n",
      "reward:  0.680419921875\n",
      "reward:  7.1219940185546875\n",
      "reward:  8.302886962890625\n",
      "reward:  7.1533966064453125\n",
      "reward:  5.6405487060546875\n",
      "reward:  3.3918914794921875\n",
      "reward:  1.94891357421875\n",
      "reward:  0.4058074951171875\n",
      "reward:  -0.2035675048828125\n",
      "reward:  6.4767303466796875\n",
      "reward:  7.841888427734375\n",
      "reward:  5.25396728515625\n",
      "reward:  2.193267822265625\n",
      "reward:  -1.072265625\n",
      "reward:  0.584686279296875\n",
      "reward:  8.1136474609375\n",
      "reward:  8.81060791015625\n",
      "reward:  5.9428253173828125\n",
      "reward:  4.008453369140625\n",
      "reward:  2.7036895751953125\n",
      "reward:  1.8235321044921875\n",
      "reward:  1.2299041748046875\n",
      "reward:  7.64788818359375\n",
      "reward:  15.557449340820312\n",
      "reward:  20.892623901367188\n",
      "reward:  24.491287231445312\n",
      "reward:  21.169815063476562\n",
      "reward:  14.485366821289062\n",
      "reward:  9.770477294921875\n",
      "reward:  7.6339569091796875\n",
      "reward:  4.765869140625\n",
      "reward:  2.042144775390625\n",
      "reward:  1.377349853515625\n",
      "reward:  -0.3998565673828125\n",
      "reward:  -2.133575439453125\n",
      "reward:  -2.0495758056640625\n",
      "reward:  -7.8802032470703125\n",
      "reward:  -8.505706787109375\n",
      "reward:  -1.1670989990234375\n",
      "reward:  -0.7873077392578125\n",
      "reward:  3.771881103515625\n",
      "reward:  -0.63116455078125\n",
      "reward:  -3.2799224853515625\n",
      "reward:  -6.489471435546875\n",
      "reward:  -4.787628173828125\n",
      "reward:  -3.2294158935546875\n",
      "reward:  -6.081939697265625\n",
      "reward:  -11.650482177734375\n",
      "reward:  -6.5062103271484375\n",
      "reward:  -2.1478118896484375\n",
      "reward:  -1.4488525390625\n",
      "reward:  -0.8891754150390625\n",
      "reward:  -6.010894775390625\n",
      "reward:  -6.8437957763671875\n",
      "reward:  -9.045242309570312\n",
      "reward:  -8.427032470703125\n",
      "reward:  -5.684295654296875\n",
      "reward:  -3.8342132568359375\n",
      "reward:  2.8249969482421875\n",
      "reward:  0.435302734375\n",
      "reward:  -5.5663604736328125\n",
      "reward:  -9.574234008789062\n",
      "reward:  -8.389190673828125\n",
      "reward:  -0.6269073486328125\n",
      "reward:  2.219451904296875\n",
      "reward:  1.4969482421875\n",
      "reward:  1.0096282958984375\n",
      "reward:  4.983917236328125\n",
      "reward:  5.6212921142578125\n",
      "reward:  -1.06353759765625\n",
      "reward:  2.644378662109375\n",
      "reward:  9.120193481445312\n",
      "reward:  8.718429565429688\n",
      "reward:  0.330078125\n",
      "reward:  -6.9595184326171875\n",
      "reward:  -12.485885620117188\n",
      "reward:  -5.7864227294921875\n",
      "reward:  4.561981201171875\n",
      "reward:  10.258926391601562\n",
      "reward:  4.8932952880859375\n",
      "reward:  1.0595703125\n",
      "reward:  -3.50665283203125\n",
      "reward:  -1.1605377197265625\n",
      "reward:  -6.83642578125\n",
      "reward:  -7.790313720703125\n",
      "reward:  -5.2547607421875\n",
      "reward:  0.7226409912109375\n",
      "reward:  6.9953155517578125\n",
      "reward:  6.5656280517578125\n",
      "reward:  -1.9478607177734375\n",
      "reward:  -4.421356201171875\n",
      "reward:  -2.9823760986328125\n",
      "reward:  1.0018157958984375\n",
      "reward:  2.219757080078125\n",
      "reward:  1.497161865234375\n",
      "reward:  3.1511993408203125\n",
      "reward:  -3.3306121826171875\n",
      "reward:  -5.558746337890625\n",
      "reward:  -2.2274627685546875\n",
      "reward:  -7.172882080078125\n",
      "reward:  -8.1270751953125\n",
      "reward:  1.2286376953125\n",
      "reward:  4.352630615234375\n",
      "reward:  9.30694580078125\n",
      "reward:  3.2520294189453125\n",
      "reward:  -1.1522979736328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:  5.1584625244140625\n",
      "reward:  0.660491943359375\n",
      "reward:  -2.6717681884765625\n",
      "reward:  4.5688934326171875\n",
      "reward:  3.39447021484375\n",
      "reward:  -1.5999298095703125\n",
      "reward:  -8.3377685546875\n",
      "reward:  -5.93707275390625\n",
      "reward:  -2.4120941162109375\n",
      "reward:  -1.6270904541015625\n",
      "reward:  -0.5937042236328125\n",
      "reward:  -4.6316375732421875\n",
      "reward:  -5.4861297607421875\n",
      "reward:  -3.700592041015625\n",
      "reward:  -7.8018035888671875\n",
      "reward:  -3.574005126953125\n",
      "reward:  4.4137115478515625\n",
      "reward:  3.932708740234375\n",
      "reward:  -1.4467315673828125\n",
      "reward:  2.8391265869140625\n",
      "reward:  -0.8355560302734375\n",
      "reward:  2.18658447265625\n",
      "reward:  3.8868560791015625\n",
      "reward:  1.1708221435546875\n",
      "reward:  0.78961181640625\n",
      "reward:  6.0829315185546875\n",
      "reward:  7.017669677734375\n",
      "reward:  4.7334136962890625\n",
      "reward:  -2.860870361328125\n",
      "reward:  0.944610595703125\n",
      "reward:  7.3983612060546875\n",
      "reward:  12.924850463867188\n",
      "reward:  5.8432769775390625\n",
      "reward:  0.7623748779296875\n",
      "reward:  -4.3825836181640625\n",
      "reward:  -5.15252685546875\n",
      "reward:  2.0748138427734375\n",
      "reward:  8.581268310546875\n",
      "reward:  10.574371337890625\n",
      "reward:  4.9294891357421875\n",
      "reward:  -1.5629730224609375\n",
      "reward:  -3.6211395263671875\n",
      "reward:  -2.442596435546875\n",
      "reward:  3.7636871337890625\n",
      "reward:  9.808975219726562\n",
      "reward:  13.37060546875\n",
      "reward:  11.34429931640625\n",
      "reward:  7.65179443359375\n",
      "reward:  5.1611328125\n",
      "reward:  3.4578399658203125\n",
      "reward:  3.2877655029296875\n",
      "reward:  3.40826416015625\n",
      "reward:  2.2987823486328125\n",
      "reward:  1.55047607421875\n",
      "reward:  6.2005615234375\n",
      "reward:  6.804473876953125\n",
      "reward:  4.589630126953125\n",
      "reward:  3.0956573486328125\n",
      "reward:  -3.0831298828125\n",
      "reward:  -0.152984619140625\n",
      "reward:  7.5056610107421875\n",
      "reward:  2.6070556640625\n",
      "reward:  -0.9507598876953125\n",
      "reward:  -5.761138916015625\n",
      "reward:  -1.384979248046875\n",
      "reward:  1.8317108154296875\n",
      "reward:  1.2353973388671875\n",
      "reward:  5.0068817138671875\n",
      "reward:  8.5396728515625\n",
      "reward:  11.64202880859375\n",
      "reward:  13.484878540039062\n",
      "reward:  12.859939575195312\n",
      "reward:  14.34405517578125\n",
      "reward:  17.561813354492188\n",
      "reward:  19.203445434570312\n",
      "reward:  15.390731811523438\n",
      "reward:  10.381179809570312\n",
      "reward:  7.002166748046875\n",
      "reward:  11.079208374023438\n",
      "reward:  8.215072631835938\n",
      "reward:  3.912200927734375\n",
      "reward:  7.4143829345703125\n",
      "reward:  7.0223236083984375\n",
      "reward:  2.933502197265625\n",
      "reward:  -0.580902099609375\n",
      "reward:  -1.252960205078125\n",
      "reward:  -7.6177520751953125\n",
      "reward:  -8.694915771484375\n",
      "reward:  -12.637481689453125\n",
      "reward:  -12.897689819335938\n",
      "reward:  -7.8664093017578125\n",
      "reward:  -11.92041015625\n",
      "reward:  -18.128341674804688\n",
      "reward:  -15.70135498046875\n",
      "reward:  -17.205169677734375\n",
      "reward:  -15.078689575195312\n",
      "reward:  -10.170883178710938\n",
      "reward:  -1.1822967529296875\n",
      "reward:  2.1842498779296875\n",
      "reward:  -3.6978607177734375\n",
      "reward:  -0.5676116943359375\n",
      "reward:  2.0411224365234375\n",
      "reward:  1.1392059326171875\n",
      "reward:  5.517364501953125\n",
      "reward:  8.111297607421875\n",
      "reward:  11.742156982421875\n",
      "reward:  1.783477783203125\n",
      "reward:  -1.18731689453125\n",
      "reward:  0.0\n",
      "reward:  -3.0879974365234375\n",
      "reward:  2.26800537109375\n",
      "reward:  1.06640625\n",
      "reward:  -1.0523529052734375\n",
      "reward:  3.4173126220703125\n",
      "reward:  -1.0868682861328125\n",
      "reward:  0.474700927734375\n",
      "reward:  7.965789794921875\n",
      "reward:  8.29229736328125\n",
      "reward:  0.7876129150390625\n",
      "reward:  -7.0242767333984375\n",
      "reward:  -12.18603515625\n",
      "reward:  -15.419692993164062\n",
      "reward:  -10.517593383789062\n",
      "reward:  -13.962249755859375\n",
      "reward:  -7.028411865234375\n",
      "reward:  -2.098480224609375\n",
      "reward:  -1.41552734375\n",
      "reward:  4.456451416015625\n",
      "reward:  5.8475341796875\n",
      "reward:  -0.8614349365234375\n",
      "reward:  1.927154541015625\n",
      "reward:  2.3487396240234375\n",
      "reward:  5.26495361328125\n",
      "reward:  5.5721435546875\n",
      "reward:  9.6942138671875\n",
      "reward:  9.655960083007812\n",
      "reward:  2.7537841796875\n",
      "reward:  -0.1167449951171875\n",
      "reward:  -0.0783538818359375\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  3.0327606201171875\n",
      "reward:  0.60528564453125\n",
      "reward:  -4.1734161376953125\n",
      "reward:  -8.127883911132812\n",
      "reward:  -5.7954864501953125\n",
      "reward:  -5.34954833984375\n",
      "reward:  -5.2011566162109375\n",
      "reward:  -0.4755706787109375\n",
      "reward:  4.259857177734375\n",
      "reward:  5.742340087890625\n",
      "reward:  5.0938568115234375\n",
      "reward:  3.4357452392578125\n",
      "reward:  5.6846923828125\n",
      "reward:  5.5557708740234375\n",
      "reward:  -0.6815185546875\n",
      "reward:  -2.7855682373046875\n",
      "reward:  -1.8789825439453125\n",
      "reward:  2.664794921875\n",
      "reward:  3.8623046875\n",
      "reward:  2.60504150390625\n",
      "reward:  -3.802154541015625\n",
      "reward:  0.0750732421875\n",
      "reward:  2.9698638916015625\n",
      "reward:  6.13037109375\n",
      "reward:  6.302276611328125\n",
      "reward:  4.25091552734375\n",
      "reward:  6.2541351318359375\n",
      "reward:  -0.2931976318359375\n",
      "reward:  2.7151031494140625\n",
      "reward:  4.983551025390625\n",
      "reward:  -0.7659912109375\n",
      "reward:  -2.6842193603515625\n",
      "reward:  -1.8106536865234375\n",
      "reward:  -0.8574981689453125\n",
      "reward:  4.4300689697265625\n",
      "reward:  0.491485595703125\n",
      "reward:  -6.5662689208984375\n",
      "reward:  -6.6917572021484375\n",
      "reward:  -4.5138092041015625\n",
      "reward:  -7.92181396484375\n",
      "reward:  -7.8330230712890625\n",
      "reward:  -5.2835845947265625\n",
      "reward:  -3.5639801025390625\n",
      "reward:  -2.404083251953125\n",
      "reward:  4.04730224609375\n",
      "reward:  1.9116668701171875\n",
      "reward:  -0.59613037109375\n",
      "reward:  -0.4021759033203125\n",
      "reward:  -5.4324798583984375\n",
      "reward:  -6.3076629638671875\n",
      "reward:  0.550689697265625\n",
      "reward:  7.700225830078125\n",
      "reward:  2.6854248046875\n",
      "reward:  4.17474365234375\n",
      "reward:  10.490158081054688\n",
      "reward:  9.718093872070312\n",
      "reward:  1.1434173583984375\n",
      "reward:  -4.81329345703125\n",
      "reward:  -10.555892944335938\n",
      "reward:  -13.536102294921875\n",
      "reward:  -7.1229705810546875\n",
      "reward:  -9.8365478515625\n",
      "reward:  -9.277481079101562\n",
      "reward:  -0.6987762451171875\n",
      "reward:  2.447906494140625\n",
      "reward:  6.6829071044921875\n",
      "reward:  2.8328399658203125\n",
      "reward:  0.7935943603515625\n",
      "reward:  5.946502685546875\n",
      "reward:  6.8526153564453125\n",
      "reward:  4.62213134765625\n",
      "reward:  3.117584228515625\n",
      "reward:  6.0350189208984375\n",
      "reward:  10.067886352539062\n",
      "reward:  5.7452392578125\n",
      "reward:  -2.1909027099609375\n",
      "reward:  -4.1200103759765625\n",
      "reward:  3.03375244140625\n",
      "reward:  -0.714202880859375\n",
      "reward:  -7.466766357421875\n",
      "Result:  302.0216827392578\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  -0.209564208984375\n",
      "reward:  -0.251495361328125\n",
      "reward:  -4.5013580322265625\n",
      "reward:  -5.7848663330078125\n",
      "reward:  -4.8514862060546875\n",
      "reward:  -0.376922607421875\n",
      "reward:  0.0\n",
      "reward:  -0.000457763671875\n",
      "reward:  0.0\n",
      "reward:  0.0\n",
      "reward:  5.9840850830078125\n",
      "reward:  8.55596923828125\n",
      "reward:  4.072021484375\n",
      "reward:  0.8675994873046875\n",
      "reward:  0.5851287841796875\n",
      "reward:  5.69671630859375\n",
      "reward:  6.62677001953125\n",
      "reward:  9.771865844726562\n",
      "reward:  4.896453857421875\n",
      "reward:  4.97882080078125\n",
      "reward:  5.4162445068359375\n",
      "reward:  -0.8282623291015625\n",
      "reward:  1.6421356201171875\n",
      "reward:  3.4595947265625\n",
      "reward:  2.33343505859375\n",
      "reward:  1.57379150390625\n",
      "reward:  1.061431884765625\n",
      "reward:  -7.2852935791015625\n",
      "reward:  -13.466873168945312\n",
      "reward:  -10.124298095703125\n",
      "reward:  -6.8291015625\n",
      "reward:  -11.425201416015625\n",
      "reward:  -4.468597412109375\n",
      "reward:  0.5665435791015625\n",
      "reward:  0.3820037841796875\n",
      "reward:  0.20233154296875\n",
      "reward:  6.557403564453125\n",
      "reward:  14.423980712890625\n",
      "reward:  11.191253662109375\n",
      "reward:  7.372467041015625\n",
      "reward:  3.30767822265625\n",
      "reward:  2.230987548828125\n",
      "reward:  7.5716400146484375\n",
      "reward:  1.6353759765625\n",
      "reward:  -0.3592529296875\n",
      "reward:  2.7793121337890625\n",
      "reward:  9.009445190429688\n",
      "reward:  9.239990234375\n",
      "reward:  6.2324066162109375\n",
      "reward:  1.4010467529296875\n",
      "reward:  -0.5269012451171875\n",
      "reward:  -2.3369293212890625\n",
      "reward:  -6.5656585693359375\n",
      "reward:  -4.821563720703125\n",
      "reward:  -8.10302734375\n",
      "reward:  -12.2073974609375\n",
      "reward:  -4.3839263916015625\n",
      "reward:  5.5167083740234375\n",
      "reward:  7.6192779541015625\n",
      "reward:  2.54571533203125\n",
      "reward:  1.7170257568359375\n",
      "reward:  3.5223541259765625\n",
      "reward:  3.5815582275390625\n",
      "reward:  8.770187377929688\n",
      "reward:  15.606979370117188\n",
      "reward:  16.464736938476562\n",
      "reward:  9.870513916015625\n",
      "reward:  11.646392822265625\n",
      "reward:  11.192474365234375\n",
      "reward:  7.5493621826171875\n",
      "reward:  2.1970977783203125\n",
      "reward:  5.4356689453125\n",
      "reward:  12.203887939453125\n",
      "reward:  -96.81593322753906\n",
      "Result:  70.54150390625\n",
      "reward:  0.0\n",
      "reward:  0.78125\n",
      "reward:  2.4580535888671875\n",
      "reward:  8.718048095703125\n",
      "reward:  8.7572021484375\n",
      "reward:  6.30126953125\n",
      "reward:  11.746597290039062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:  11.6307373046875\n",
      "reward:  7.845001220703125\n",
      "reward:  5.29144287109375\n",
      "reward:  10.682815551757812\n",
      "reward:  10.94134521484375\n",
      "reward:  5.40814208984375\n",
      "reward:  0.46466064453125\n",
      "reward:  -3.1175994873046875\n",
      "reward:  -2.643341064453125\n",
      "reward:  -1.783111572265625\n",
      "reward:  5.697479248046875\n",
      "reward:  7.466552734375\n",
      "reward:  5.0362396240234375\n",
      "reward:  3.396942138671875\n",
      "reward:  2.2911834716796875\n",
      "reward:  5.30010986328125\n",
      "reward:  11.485504150390625\n",
      "reward:  7.1110076904296875\n",
      "reward:  2.8246307373046875\n",
      "reward:  1.4826202392578125\n",
      "reward:  5.8907928466796875\n",
      "reward:  3.792510986328125\n",
      "reward:  0.924072265625\n",
      "reward:  -2.8845062255859375\n",
      "reward:  -3.0659027099609375\n",
      "reward:  0.96014404296875\n",
      "reward:  8.611419677734375\n",
      "reward:  15.52911376953125\n",
      "reward:  13.821548461914062\n",
      "reward:  5.1097564697265625\n",
      "reward:  5.164398193359375\n",
      "reward:  9.577880859375\n",
      "reward:  15.5732421875\n",
      "reward:  19.719818115234375\n",
      "reward:  14.89141845703125\n",
      "reward:  10.044357299804688\n",
      "reward:  9.803237915039062\n",
      "reward:  5.17437744140625\n",
      "reward:  1.8998260498046875\n",
      "reward:  -2.473419189453125\n",
      "reward:  -3.6402435302734375\n",
      "reward:  -6.2102813720703125\n",
      "reward:  2.031280517578125\n",
      "reward:  4.80810546875\n",
      "reward:  8.983383178710938\n",
      "reward:  8.995468139648438\n"
     ]
    },
    {
     "ename": "ViZDoomUnexpectedExitException",
     "evalue": "Controlled ViZDoom instance exited unexpectedly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mViZDoomUnexpectedExitException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mscreen_buffer\n\u001b[1;32m      7\u001b[0m info \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mgame_variables\n\u001b[0;32m----> 8\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward: \u001b[39m\u001b[38;5;124m'\u001b[39m, reward)\n\u001b[1;32m     10\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.02\u001b[39m)\n",
      "\u001b[0;31mViZDoomUnexpectedExitException\u001b[0m: Controlled ViZDoom instance exited unexpectedly."
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for i in range(episodes):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        state = game.get_state()\n",
    "        img = state.screen_buffer\n",
    "        info = state.game_variables\n",
    "        reward = game.make_action(random.choice(actions),4)\n",
    "        print('reward: ', reward)\n",
    "        time.sleep(0.02)\n",
    "    print(\"Result: \", game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4644cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c5d8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ed8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vizDoomGym(Env):\n",
    "    \n",
    "    def __init__(self, render=False, config='/Users/raghavsuri/Desktop/RLDOOM/Github/ViZDoom-master/scenarios/deadly_corridor.cfg'): ##Function called on starting env\n",
    "        \n",
    "        ##inherit from env class\n",
    "        super().__init__()\n",
    "        \n",
    "        #Game setup\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config(config)\n",
    "\n",
    "        \n",
    "        if render ==False:\n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "\n",
    "            \n",
    "            \n",
    "        self.game.init()\n",
    "        \n",
    "        \n",
    "        ##Creating action and observatio space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100,160,1), dtype=np.uint8)\n",
    "        self.action_space = Discrete(7)\n",
    "        \n",
    "        self.damage_taken = 0\n",
    "        self.hitcount = 0\n",
    "        self.ammo = 52\n",
    "        \n",
    "    \n",
    "    def step(self, action): ## Taking steps in env\n",
    "        \n",
    "        actions = np.identity(7)\n",
    "        movement_reward = self.game.make_action(actions[action], 4)\n",
    "        \n",
    "        reward = 0\n",
    "        \n",
    "        \n",
    "        if self.game.get_state():\n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.grayscale(state)\n",
    "\n",
    "            \n",
    "            #Reward shaping\n",
    "            \n",
    "            game_variables = self.game.get_state().game_variables\n",
    "            health, damage_taken, hitcount, ammo = game_variables\n",
    "            \n",
    "            \n",
    "            damage_taken_delta = -damage_taken + self.damage_taken\n",
    "            self.damage_taken = damage_taken\n",
    "            hitcount_delta = hitcount - self.hitcount\n",
    "            self.hitcount = hitcount\n",
    "            _,__,___,ammo = game_variables\n",
    "            \n",
    "            ammo_delta = ammo - self.ammo\n",
    "            self.ammo = ammo\n",
    "            \n",
    "            \n",
    "            reward = movement_reward + damage_taken_delta*10 + hitcount_delta*200 + ammo_delta*5\n",
    "            \n",
    "            \n",
    "            info = ammo\n",
    "            #info = {'info': info}\n",
    "            \n",
    "        else:\n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = None\n",
    "            \n",
    "\n",
    "        done = self.game.is_episode_finished()\n",
    "        if not done:\n",
    "            \n",
    "            truncated = self.game.is_episode_finished()\n",
    "        else: \n",
    "            truncated = False\n",
    "            \n",
    "        info = {'info': info}            \n",
    "        return state, reward, done, truncated, info\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    def render(): ## defining how to render env/game\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def reset(self, seed=0): ## starting new game\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        ammo  = self.game.get_state().game_variables[0]\n",
    "        info = {'ammo': ammo}\n",
    "            \n",
    "        return self.grayscale(state), info\n",
    "            \n",
    "    \n",
    "    def grayscale(self, observation): ## grayscale the game frame and resize it \n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160,100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100,160,1))\n",
    "        return state\n",
    "\n",
    "    \n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65672f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = vizDoomGym(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0427eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3fae35a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[32],\n",
       "         [33],\n",
       "         [25],\n",
       "         ...,\n",
       "         [27],\n",
       "         [23],\n",
       "         [24]],\n",
       " \n",
       "        [[27],\n",
       "         [33],\n",
       "         [23],\n",
       "         ...,\n",
       "         [24],\n",
       "         [24],\n",
       "         [24]],\n",
       " \n",
       "        [[20],\n",
       "         [35],\n",
       "         [23],\n",
       "         ...,\n",
       "         [24],\n",
       "         [24],\n",
       "         [24]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[75],\n",
       "         [63],\n",
       "         [62],\n",
       "         ...,\n",
       "         [44],\n",
       "         [71],\n",
       "         [60]],\n",
       " \n",
       "        [[15],\n",
       "         [48],\n",
       "         [47],\n",
       "         ...,\n",
       "         [49],\n",
       "         [69],\n",
       "         [47]],\n",
       " \n",
       "        [[22],\n",
       "         [14],\n",
       "         [26],\n",
       "         ...,\n",
       "         [57],\n",
       "         [37],\n",
       "         [39]]], dtype=uint8),\n",
       " -40.0,\n",
       " False,\n",
       " False,\n",
       " {'info': 52.0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a1782ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d08ad89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "6c2efed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 160, 1)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4455f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4673cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.moveaxis(state,0,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18309ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       " \n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       " \n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       " \n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       " \n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]),\n",
       " 99.0,\n",
       " True,\n",
       " False,\n",
       " 0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "89a0600b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 160, 1)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb6d0252",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8058695880>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cv2.cvtColor(state[0], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77e34f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f7be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01904076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m env_checker\u001b[38;5;241m.\u001b[39mcheck_env(\u001b[43menv\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceabd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50627e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Callback to save model\n",
    "import os\n",
    "# Import callback class from stable baselines3 for saving and callback of rl model\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2403005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    \n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def __init__callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "            \n",
    "    \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "    \n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10cac8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_corridor_5'\n",
    "LOG_DIR = './logs/log_corridor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74fe5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50942d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "00ffd056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Model using Curriculum Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42217a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82978e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7f2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b648bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdb400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5846a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = vizDoomGym(config='/Users/raghavsuri/Desktop/RLDOOM/Github/ViZDoom-master/scenarios/deadly_corridor.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e725d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "#model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=4096)\n",
    "##Hyperparamater Tuning\n",
    "# learning_rate = 0.00001\n",
    "# n_steps(batch size) = 8192 :  8192/64=128\n",
    "# clip_range=.1     ,10% - clips out the gradient in PPO algo\n",
    "# gamma =.95        , 95% - discount factor\n",
    "# gae_lambda=.9     , smoothing parameter used to calculate advantage\n",
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4b35a6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_corridor/PPO_18\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 204      |\n",
      "|    ep_rew_mean     | 15.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 168      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 173         |\n",
      "|    ep_rew_mean          | 84.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009406838 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 2.45e-05    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 6.13e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.00595     |\n",
      "|    value_loss           | 1.21e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012620021 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0402      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.2e+03     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | 0.00478     |\n",
      "|    value_loss           | 1.47e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 138        |\n",
      "|    ep_rew_mean          | 190        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01325242 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 0.076      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 7.2e+03    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | 0.00139    |\n",
      "|    value_loss           | 1.26e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghavsuri/opt/anaconda3/envs/RLDOOM/lib/python3.9/site-packages/stable_baselines3/common/save_util.py:283: UserWarning: Path 'train/train_corridor_5' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 131         |\n",
      "|    ep_rew_mean          | 243         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017719103 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 8.17e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00048    |\n",
      "|    value_loss           | 1.94e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 112        |\n",
      "|    ep_rew_mean          | 295        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01784069 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.84      |\n",
      "|    explained_variance   | 0.196      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.12e+04   |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.00409   |\n",
      "|    value_loss           | 2.03e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 83.8        |\n",
      "|    ep_rew_mean          | 415         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025262833 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 6.26e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.000498   |\n",
      "|    value_loss           | 1.85e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.6        |\n",
      "|    ep_rew_mean          | 524         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020509478 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 8.71e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.0131      |\n",
      "|    value_loss           | 2.14e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.6       |\n",
      "|    ep_rew_mean          | 629        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 493        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07239585 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.53      |\n",
      "|    explained_variance   | 0.311      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.7e+04    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | 0.0157     |\n",
      "|    value_loss           | 2.6e+04    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 53.5       |\n",
      "|    ep_rew_mean          | 659        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 549        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03625252 |\n",
      "|    clip_fraction        | 0.45       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | 0.262      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.41e+04   |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | 0.0366     |\n",
      "|    value_loss           | 2.76e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 52.6       |\n",
      "|    ep_rew_mean          | 734        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 600        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24868834 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0.298      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.48e+04   |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | 0.0296     |\n",
      "|    value_loss           | 2.84e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 49.8      |\n",
      "|    ep_rew_mean          | 941       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 651       |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.5692196 |\n",
      "|    clip_fraction        | 0.638     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.581    |\n",
      "|    explained_variance   | 0.193     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.43e+04  |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | 0.0585    |\n",
      "|    value_loss           | 2.81e+04  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 44.8     |\n",
      "|    ep_rew_mean          | 1.27e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 37       |\n",
      "|    iterations           | 13       |\n",
      "|    time_elapsed         | 700      |\n",
      "|    total_timesteps      | 26624    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.823838 |\n",
      "|    clip_fraction        | 0.14     |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.201   |\n",
      "|    explained_variance   | 0.213    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 2.92e+04 |\n",
      "|    n_updates            | 120      |\n",
      "|    policy_gradient_loss | 0.0202   |\n",
      "|    value_loss           | 4.79e+04 |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 42.6       |\n",
      "|    ep_rew_mean          | 1.48e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 753        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04536313 |\n",
      "|    clip_fraction        | 0.00601    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0198    |\n",
      "|    explained_variance   | 0.00802    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.73e+04   |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | 0.00407    |\n",
      "|    value_loss           | 6.11e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.2      |\n",
      "|    ep_rew_mean          | 1.5e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 810       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000106 |\n",
      "|    explained_variance   | 0.0891    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.75e+04  |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | 4.28e-07  |\n",
      "|    value_loss           | 6.55e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.1      |\n",
      "|    ep_rew_mean          | 1.44e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 860       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -7.16e-06 |\n",
      "|    explained_variance   | 0.207     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.25e+04  |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -7.22e-08 |\n",
      "|    value_loss           | 6.41e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42        |\n",
      "|    ep_rew_mean          | 1.44e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 913       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.67e-06 |\n",
      "|    explained_variance   | 0.306     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.83e+04  |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -2.2e-08  |\n",
      "|    value_loss           | 5.45e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.1      |\n",
      "|    ep_rew_mean          | 1.47e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 975       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.71e-06 |\n",
      "|    explained_variance   | 0.251     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.26e+04  |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | 1.27e-08  |\n",
      "|    value_loss           | 6.48e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.3      |\n",
      "|    ep_rew_mean          | 1.45e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 1029      |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -7.79e-07 |\n",
      "|    explained_variance   | 0.329     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.75e+04  |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | 8.6e-10   |\n",
      "|    value_loss           | 6.64e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.4      |\n",
      "|    ep_rew_mean          | 1.47e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 1082      |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.57e-07 |\n",
      "|    explained_variance   | 0.368     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.03e+04  |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -1.13e-09 |\n",
      "|    value_loss           | 6.36e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.1      |\n",
      "|    ep_rew_mean          | 1.45e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 1134      |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -7.01e-07 |\n",
      "|    explained_variance   | 0.365     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.21e+04  |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | 5.62e-10  |\n",
      "|    value_loss           | 6.79e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.2      |\n",
      "|    ep_rew_mean          | 1.42e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 1185      |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.78e-07 |\n",
      "|    explained_variance   | 0.501     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2e+04     |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | 5.88e-10  |\n",
      "|    value_loss           | 5e+04     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.2      |\n",
      "|    ep_rew_mean          | 1.49e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 1241      |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.13e-06 |\n",
      "|    explained_variance   | 0.395     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.34e+04  |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | 6.3e-10   |\n",
      "|    value_loss           | 6.1e+04   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 41.9      |\n",
      "|    ep_rew_mean          | 1.48e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 1296      |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.9e-06  |\n",
      "|    explained_variance   | 0.291     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.16e+04  |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -6.11e-10 |\n",
      "|    value_loss           | 6.79e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 41.8      |\n",
      "|    ep_rew_mean          | 1.43e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 1350      |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.53e-07 |\n",
      "|    explained_variance   | 0.394     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.41e+04  |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | 1.22e-09  |\n",
      "|    value_loss           | 5.75e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42        |\n",
      "|    ep_rew_mean          | 1.37e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 1400      |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.05e-06 |\n",
      "|    explained_variance   | 0.418     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.28e+04  |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | 1.05e-09  |\n",
      "|    value_loss           | 5.18e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.1      |\n",
      "|    ep_rew_mean          | 1.45e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 1452      |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.44e-06 |\n",
      "|    explained_variance   | 0.524     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.57e+04  |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | 5.05e-10  |\n",
      "|    value_loss           | 4.33e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.3      |\n",
      "|    ep_rew_mean          | 1.49e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 1504      |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02e-05 |\n",
      "|    explained_variance   | 0.211     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.58e+04  |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -5e-08    |\n",
      "|    value_loss           | 6.75e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.2      |\n",
      "|    ep_rew_mean          | 1.49e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 1558      |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.21e-07 |\n",
      "|    explained_variance   | 0.384     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.07e+04  |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -1.96e-08 |\n",
      "|    value_loss           | 5.26e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.2      |\n",
      "|    ep_rew_mean          | 1.5e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 1615      |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.96e-06 |\n",
      "|    explained_variance   | 0.361     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.13e+04  |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | 8.5e-10   |\n",
      "|    value_loss           | 5.83e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fd7de381fd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=60000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "790ba05f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor/PPO_19\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.5     |\n",
      "|    ep_rew_mean     | 977      |\n",
      "| time/              |          |\n",
      "|    fps             | 176      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.2      |\n",
      "|    ep_rew_mean          | 1.06e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.23e-05 |\n",
      "|    explained_variance   | 0.378     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.57e+04  |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | 5.11e-08  |\n",
      "|    value_loss           | 5.78e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.7      |\n",
      "|    ep_rew_mean          | 1.12e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 50        |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 122       |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000159 |\n",
      "|    explained_variance   | 0.164     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.18e+04  |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -5.43e-07 |\n",
      "|    value_loss           | 6.68e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35        |\n",
      "|    ep_rew_mean          | 1.09e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 46        |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 177       |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.42e-05 |\n",
      "|    explained_variance   | 0.248     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.91e+04  |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | 5.42e-08  |\n",
      "|    value_loss           | 6.1e+04   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.6      |\n",
      "|    ep_rew_mean          | 1.02e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 44        |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 232       |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.13e-05 |\n",
      "|    explained_variance   | 0.304     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.65e+04  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | 3.93e-08  |\n",
      "|    value_loss           | 5.41e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.7      |\n",
      "|    ep_rew_mean          | 1.07e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 42        |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 286       |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -7.73e-05 |\n",
      "|    explained_variance   | 0.319     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.2e+04   |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | 3.08e-08  |\n",
      "|    value_loss           | 4.54e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.5      |\n",
      "|    ep_rew_mean          | 1.08e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 41        |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 344       |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000251 |\n",
      "|    explained_variance   | 0.228     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.04e+04  |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | 2.51e-07  |\n",
      "|    value_loss           | 6.59e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35        |\n",
      "|    ep_rew_mean          | 1.02e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 40        |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 401       |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000572 |\n",
      "|    explained_variance   | 0.221     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.85e+04  |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | 1.34e-07  |\n",
      "|    value_loss           | 5.56e+04  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.9         |\n",
      "|    ep_rew_mean          | 1.06e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 40           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 454          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013236753 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000147    |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+04     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -1.2e-05     |\n",
      "|    value_loss           | 3.79e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.3      |\n",
      "|    ep_rew_mean          | 1.09e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 40        |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 507       |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000172 |\n",
      "|    explained_variance   | 0.314     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.81e+04  |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | -1.72e-07 |\n",
      "|    value_loss           | 4.58e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.8      |\n",
      "|    ep_rew_mean          | 1.12e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 40        |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 561       |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000238 |\n",
      "|    explained_variance   | 0.271     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.75e+04  |\n",
      "|    n_updates            | 400       |\n",
      "|    policy_gradient_loss | 2.46e-07  |\n",
      "|    value_loss           | 5.61e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.4      |\n",
      "|    ep_rew_mean          | 1.08e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 39        |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 620       |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.78e-05 |\n",
      "|    explained_variance   | 0.337     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.02e+04  |\n",
      "|    n_updates            | 410       |\n",
      "|    policy_gradient_loss | 9.64e-08  |\n",
      "|    value_loss           | 4.96e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35        |\n",
      "|    ep_rew_mean          | 1.06e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 39        |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 675       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000218 |\n",
      "|    explained_variance   | 0.281     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.77e+04  |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | 2.5e-07   |\n",
      "|    value_loss           | 5.51e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.3      |\n",
      "|    ep_rew_mean          | 1.05e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 39        |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 733       |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000299 |\n",
      "|    explained_variance   | 0.358     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.13e+04  |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | 4.14e-07  |\n",
      "|    value_loss           | 4.29e+04  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 36.5     |\n",
      "|    ep_rew_mean          | 1.1e+03  |\n",
      "| time/                   |          |\n",
      "|    fps                  | 38       |\n",
      "|    iterations           | 15       |\n",
      "|    time_elapsed         | 792      |\n",
      "|    total_timesteps      | 30720    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00014 |\n",
      "|    explained_variance   | 0.355    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.72e+04 |\n",
      "|    n_updates            | 440      |\n",
      "|    policy_gradient_loss | 7.67e-08 |\n",
      "|    value_loss           | 4.36e+04 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36.2      |\n",
      "|    ep_rew_mean          | 1.12e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 845       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000215 |\n",
      "|    explained_variance   | 0.387     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.57e+04  |\n",
      "|    n_updates            | 450       |\n",
      "|    policy_gradient_loss | 3.28e-07  |\n",
      "|    value_loss           | 3.74e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.3      |\n",
      "|    ep_rew_mean          | 1.05e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 903       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000188 |\n",
      "|    explained_variance   | 0.303     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.53e+04  |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | 4.03e-07  |\n",
      "|    value_loss           | 5.58e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.8      |\n",
      "|    ep_rew_mean          | 1.11e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 969       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.24e-05 |\n",
      "|    explained_variance   | 0.381     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.75e+04  |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | 1.25e-07  |\n",
      "|    value_loss           | 4.38e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.9      |\n",
      "|    ep_rew_mean          | 1.09e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 1024      |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000152 |\n",
      "|    explained_variance   | 0.318     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.77e+04  |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | 3.38e-07  |\n",
      "|    value_loss           | 5.25e+04  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.1         |\n",
      "|    ep_rew_mean          | 1.11e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 37           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 1084         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.566996e-10 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000862    |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 4.16e+04     |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -6.7e-07     |\n",
      "|    value_loss           | 6.58e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.1         |\n",
      "|    ep_rew_mean          | 1.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 37           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 1155         |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.820766e-11 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000307    |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.54e+04     |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | 2.36e-06     |\n",
      "|    value_loss           | 4.81e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36.2      |\n",
      "|    ep_rew_mean          | 1.11e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 1214      |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000219 |\n",
      "|    explained_variance   | 0.336     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.86e+04  |\n",
      "|    n_updates            | 510       |\n",
      "|    policy_gradient_loss | 2.81e-07  |\n",
      "|    value_loss           | 4.99e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.3      |\n",
      "|    ep_rew_mean          | 1.06e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 1270      |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000426 |\n",
      "|    explained_variance   | 0.357     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.09e+04  |\n",
      "|    n_updates            | 520       |\n",
      "|    policy_gradient_loss | 5.11e-07  |\n",
      "|    value_loss           | 4.49e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.7      |\n",
      "|    ep_rew_mean          | 1.1e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 36        |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 1329      |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000709 |\n",
      "|    explained_variance   | 0.282     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.09e+04  |\n",
      "|    n_updates            | 530       |\n",
      "|    policy_gradient_loss | 2.21e-07  |\n",
      "|    value_loss           | 5.06e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.3      |\n",
      "|    ep_rew_mean          | 1.08e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 1383      |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000241 |\n",
      "|    explained_variance   | 0.36      |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.5e+04   |\n",
      "|    n_updates            | 540       |\n",
      "|    policy_gradient_loss | 2.33e-07  |\n",
      "|    value_loss           | 4.22e+04  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 34.7          |\n",
      "|    ep_rew_mean          | 1.05e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 37            |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 1435          |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3655746e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00115      |\n",
      "|    explained_variance   | 0.334         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.98e+04      |\n",
      "|    n_updates            | 550           |\n",
      "|    policy_gradient_loss | -8.43e-07     |\n",
      "|    value_loss           | 4.27e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.1         |\n",
      "|    ep_rew_mean          | 1.05e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 37           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 1492         |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.355105e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000123    |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.57e+04     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -2.25e-06    |\n",
      "|    value_loss           | 3.44e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 35            |\n",
      "|    ep_rew_mean          | 1.12e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 36            |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 1558          |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2427336e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00193      |\n",
      "|    explained_variance   | 0.226         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 2.53e+04      |\n",
      "|    n_updates            | 570           |\n",
      "|    policy_gradient_loss | -4.26e-06     |\n",
      "|    value_loss           | 5.69e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.8         |\n",
      "|    ep_rew_mean          | 1.1e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 36           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 1612         |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025498655 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000301    |\n",
      "|    explained_variance   | 0.201        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 3.64e+04     |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -5.51e-06    |\n",
      "|    value_loss           | 6.45e+04     |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 35.1     |\n",
      "|    ep_rew_mean          | 1.02e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 36       |\n",
      "|    iterations           | 30       |\n",
      "|    time_elapsed         | 1671     |\n",
      "|    total_timesteps      | 61440    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -7.8e-06 |\n",
      "|    explained_variance   | 0.294    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 2.64e+04 |\n",
      "|    n_updates            | 590      |\n",
      "|    policy_gradient_loss | 1.36e-08 |\n",
      "|    value_loss           | 4.58e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fd7de381fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = vizDoomGym(config='/Users/raghavsuri/Desktop/RLDOOM/Github/ViZDoom-master/scenarios/deadly_corridor2.cfg')\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=60000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3206292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor/PPO_20\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35       |\n",
      "|    ep_rew_mean     | 1.03e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 169      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.3      |\n",
      "|    ep_rew_mean          | 1.08e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 53        |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.44e-06 |\n",
      "|    explained_variance   | 0.419     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.93e+04  |\n",
      "|    n_updates            | 610       |\n",
      "|    policy_gradient_loss | 3.52e-09  |\n",
      "|    value_loss           | 3.92e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.6      |\n",
      "|    ep_rew_mean          | 1.12e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 44        |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 137       |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.25e-05 |\n",
      "|    explained_variance   | 0.285     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.76e+04  |\n",
      "|    n_updates            | 620       |\n",
      "|    policy_gradient_loss | -5e-08    |\n",
      "|    value_loss           | 5.3e+04   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.3      |\n",
      "|    ep_rew_mean          | 1.1e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 41        |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 197       |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.12e-06 |\n",
      "|    explained_variance   | 0.284     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.1e+04   |\n",
      "|    n_updates            | 630       |\n",
      "|    policy_gradient_loss | -3.58e-09 |\n",
      "|    value_loss           | 6.27e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 33.3      |\n",
      "|    ep_rew_mean          | 992       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 264       |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.92e-05 |\n",
      "|    explained_variance   | 0.291     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.19e+04  |\n",
      "|    n_updates            | 640       |\n",
      "|    policy_gradient_loss | -4.85e-08 |\n",
      "|    value_loss           | 5.09e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.5      |\n",
      "|    ep_rew_mean          | 1.03e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 36        |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 333       |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.48e-05 |\n",
      "|    explained_variance   | 0.42      |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.42e+04  |\n",
      "|    n_updates            | 650       |\n",
      "|    policy_gradient_loss | 1.83e-08  |\n",
      "|    value_loss           | 4.05e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36.5      |\n",
      "|    ep_rew_mean          | 1.14e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 36        |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 395       |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.75e-06 |\n",
      "|    explained_variance   | 0.344     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.84e+04  |\n",
      "|    n_updates            | 660       |\n",
      "|    policy_gradient_loss | -1.09e-08 |\n",
      "|    value_loss           | 4.21e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36.2      |\n",
      "|    ep_rew_mean          | 1.12e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 36        |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 451       |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.62e-05 |\n",
      "|    explained_variance   | 0.256     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.09e+04  |\n",
      "|    n_updates            | 670       |\n",
      "|    policy_gradient_loss | 1.45e-09  |\n",
      "|    value_loss           | 5.09e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.5      |\n",
      "|    ep_rew_mean          | 1.07e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 514       |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.47e-05 |\n",
      "|    explained_variance   | 0.323     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.18e+04  |\n",
      "|    n_updates            | 680       |\n",
      "|    policy_gradient_loss | 9.27e-08  |\n",
      "|    value_loss           | 4.08e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.5      |\n",
      "|    ep_rew_mean          | 1.06e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 583       |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.48e-05 |\n",
      "|    explained_variance   | 0.264     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.84e+04  |\n",
      "|    n_updates            | 690       |\n",
      "|    policy_gradient_loss | 5.47e-08  |\n",
      "|    value_loss           | 5.35e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.4      |\n",
      "|    ep_rew_mean          | 1.08e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 646       |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000139 |\n",
      "|    explained_variance   | 0.186     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.73e+04  |\n",
      "|    n_updates            | 700       |\n",
      "|    policy_gradient_loss | -6.98e-07 |\n",
      "|    value_loss           | 5.1e+04   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36.5      |\n",
      "|    ep_rew_mean          | 1.15e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 707       |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -7.55e-05 |\n",
      "|    explained_variance   | 0.342     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.18e+04  |\n",
      "|    n_updates            | 710       |\n",
      "|    policy_gradient_loss | -4.5e-08  |\n",
      "|    value_loss           | 4.45e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.3      |\n",
      "|    ep_rew_mean          | 1.1e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 763       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000127 |\n",
      "|    explained_variance   | 0.183     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.76e+04  |\n",
      "|    n_updates            | 720       |\n",
      "|    policy_gradient_loss | 5.28e-08  |\n",
      "|    value_loss           | 6.46e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.2      |\n",
      "|    ep_rew_mean          | 1.05e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 827       |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.68e-05 |\n",
      "|    explained_variance   | 0.332     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.62e+04  |\n",
      "|    n_updates            | 730       |\n",
      "|    policy_gradient_loss | 1.56e-07  |\n",
      "|    value_loss           | 4.25e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.4      |\n",
      "|    ep_rew_mean          | 1.06e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 886       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.38e-05 |\n",
      "|    explained_variance   | 0.337     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.78e+04  |\n",
      "|    n_updates            | 740       |\n",
      "|    policy_gradient_loss | 3.58e-08  |\n",
      "|    value_loss           | 4.16e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.4      |\n",
      "|    ep_rew_mean          | 1.09e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 942       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.44e-06 |\n",
      "|    explained_variance   | 0.337     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.02e+04  |\n",
      "|    n_updates            | 750       |\n",
      "|    policy_gradient_loss | -4.83e-08 |\n",
      "|    value_loss           | 5.1e+04   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.5      |\n",
      "|    ep_rew_mean          | 1.09e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 998       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.84e-05 |\n",
      "|    explained_variance   | 0.303     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.33e+04  |\n",
      "|    n_updates            | 760       |\n",
      "|    policy_gradient_loss | -1.33e-07 |\n",
      "|    value_loss           | 4e+04     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36        |\n",
      "|    ep_rew_mean          | 1.11e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 1068      |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.68e-05 |\n",
      "|    explained_variance   | 0.322     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.25e+04  |\n",
      "|    n_updates            | 770       |\n",
      "|    policy_gradient_loss | 3.79e-08  |\n",
      "|    value_loss           | 4.65e+04  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 35.1     |\n",
      "|    ep_rew_mean          | 1.07e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 34       |\n",
      "|    iterations           | 19       |\n",
      "|    time_elapsed         | 1128     |\n",
      "|    total_timesteps      | 38912    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -3.4e-05 |\n",
      "|    explained_variance   | 0.3      |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.57e+04 |\n",
      "|    n_updates            | 780      |\n",
      "|    policy_gradient_loss | 6.21e-08 |\n",
      "|    value_loss           | 4.31e+04 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.4      |\n",
      "|    ep_rew_mean          | 1.06e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 1181      |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.49e-06 |\n",
      "|    explained_variance   | 0.369     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.9e+04   |\n",
      "|    n_updates            | 790       |\n",
      "|    policy_gradient_loss | 6.69e-09  |\n",
      "|    value_loss           | 4.38e+04  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 36       |\n",
      "|    ep_rew_mean          | 1.12e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 34       |\n",
      "|    iterations           | 21       |\n",
      "|    time_elapsed         | 1233     |\n",
      "|    total_timesteps      | 43008    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00012 |\n",
      "|    explained_variance   | 0.296    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.87e+04 |\n",
      "|    n_updates            | 800      |\n",
      "|    policy_gradient_loss | 8.34e-08 |\n",
      "|    value_loss           | 5.39e+04 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36        |\n",
      "|    ep_rew_mean          | 1.11e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 1290      |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000381 |\n",
      "|    explained_variance   | 0.287     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.15e+04  |\n",
      "|    n_updates            | 810       |\n",
      "|    policy_gradient_loss | 6.26e-07  |\n",
      "|    value_loss           | 4.92e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.9      |\n",
      "|    ep_rew_mean          | 1.08e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 1344      |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.52e-05 |\n",
      "|    explained_variance   | 0.311     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.3e+04   |\n",
      "|    n_updates            | 820       |\n",
      "|    policy_gradient_loss | -2.38e-07 |\n",
      "|    value_loss           | 4.98e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.5      |\n",
      "|    ep_rew_mean          | 1.1e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 1398      |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.62e-06 |\n",
      "|    explained_variance   | 0.35      |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.77e+04  |\n",
      "|    n_updates            | 830       |\n",
      "|    policy_gradient_loss | 7.21e-08  |\n",
      "|    value_loss           | 4.57e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36        |\n",
      "|    ep_rew_mean          | 1.13e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 1452      |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000528 |\n",
      "|    explained_variance   | 0.242     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.37e+04  |\n",
      "|    n_updates            | 840       |\n",
      "|    policy_gradient_loss | -5.14e-07 |\n",
      "|    value_loss           | 5.27e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35        |\n",
      "|    ep_rew_mean          | 1.1e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 1512      |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.75e-05 |\n",
      "|    explained_variance   | 0.315     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.69e+04  |\n",
      "|    n_updates            | 850       |\n",
      "|    policy_gradient_loss | 1.1e-06   |\n",
      "|    value_loss           | 5.02e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.4      |\n",
      "|    ep_rew_mean          | 1.04e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 1569      |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.36e-05 |\n",
      "|    explained_variance   | 0.334     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.3e+04   |\n",
      "|    n_updates            | 860       |\n",
      "|    policy_gradient_loss | 3.74e-08  |\n",
      "|    value_loss           | 4.94e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.7      |\n",
      "|    ep_rew_mean          | 1.14e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 1626      |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000211 |\n",
      "|    explained_variance   | 0.374     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 9.26e+03  |\n",
      "|    n_updates            | 870       |\n",
      "|    policy_gradient_loss | 4.83e-07  |\n",
      "|    value_loss           | 3.91e+04  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 35       |\n",
      "|    ep_rew_mean          | 1.16e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 35       |\n",
      "|    iterations           | 29       |\n",
      "|    time_elapsed         | 1679     |\n",
      "|    total_timesteps      | 59392    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00049 |\n",
      "|    explained_variance   | 0.22     |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 3.96e+04 |\n",
      "|    n_updates            | 880      |\n",
      "|    policy_gradient_loss | 3.88e-07 |\n",
      "|    value_loss           | 6.71e+04 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.5      |\n",
      "|    ep_rew_mean          | 1.1e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 1736      |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000307 |\n",
      "|    explained_variance   | 0.271     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.04e+04  |\n",
      "|    n_updates            | 890       |\n",
      "|    policy_gradient_loss | 3.53e-07  |\n",
      "|    value_loss           | 5.81e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fd7de381fd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = vizDoomGym(config='/Users/raghavsuri/Desktop/RLDOOM/Github/ViZDoom-master/scenarios/deadly_corridor3.cfg')\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=60000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd4e29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3026870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor/PPO_21\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.4     |\n",
      "|    ep_rew_mean     | 1.09e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 186      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35        |\n",
      "|    ep_rew_mean          | 1.08e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 61        |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000337 |\n",
      "|    explained_variance   | 0.219     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.14e+04  |\n",
      "|    n_updates            | 910       |\n",
      "|    policy_gradient_loss | 6.23e-07  |\n",
      "|    value_loss           | 6.3e+04   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.7      |\n",
      "|    ep_rew_mean          | 1.04e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 48        |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 127       |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000152 |\n",
      "|    explained_variance   | 0.279     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.15e+04  |\n",
      "|    n_updates            | 920       |\n",
      "|    policy_gradient_loss | 7.11e-08  |\n",
      "|    value_loss           | 4.97e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.5      |\n",
      "|    ep_rew_mean          | 1.04e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 44        |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 185       |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.59e-05 |\n",
      "|    explained_variance   | 0.348     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.81e+04  |\n",
      "|    n_updates            | 930       |\n",
      "|    policy_gradient_loss | -8.08e-07 |\n",
      "|    value_loss           | 4.36e+04  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 34.9          |\n",
      "|    ep_rew_mean          | 1.04e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 41            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 245           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9092113e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0028       |\n",
      "|    explained_variance   | 0.273         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 2.56e+04      |\n",
      "|    n_updates            | 940           |\n",
      "|    policy_gradient_loss | -1.12e-05     |\n",
      "|    value_loss           | 4.2e+04       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 34.8          |\n",
      "|    ep_rew_mean          | 1.03e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 40            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 300           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4319085e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00101      |\n",
      "|    explained_variance   | 0.347         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 2.2e+04       |\n",
      "|    n_updates            | 950           |\n",
      "|    policy_gradient_loss | 1.24e-06      |\n",
      "|    value_loss           | 4.41e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 34.8          |\n",
      "|    ep_rew_mean          | 1.02e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 40            |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 356           |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1624146e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00198      |\n",
      "|    explained_variance   | 0.291         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 4.16e+04      |\n",
      "|    n_updates            | 960           |\n",
      "|    policy_gradient_loss | 3.23e-06      |\n",
      "|    value_loss           | 4.38e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 35.2          |\n",
      "|    ep_rew_mean          | 1.08e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 40            |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 408           |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3283064e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.39e-05     |\n",
      "|    explained_variance   | 0.321         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 2.15e+04      |\n",
      "|    n_updates            | 970           |\n",
      "|    policy_gradient_loss | 1.73e-07      |\n",
      "|    value_loss           | 4.05e+04      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.5      |\n",
      "|    ep_rew_mean          | 1.1e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 39        |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 469       |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.56e-05 |\n",
      "|    explained_variance   | 0.302     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.79e+04  |\n",
      "|    n_updates            | 980       |\n",
      "|    policy_gradient_loss | 1.44e-07  |\n",
      "|    value_loss           | 5.57e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.6      |\n",
      "|    ep_rew_mean          | 1.07e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 539       |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000134 |\n",
      "|    explained_variance   | 0.323     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.53e+04  |\n",
      "|    n_updates            | 990       |\n",
      "|    policy_gradient_loss | 3.45e-07  |\n",
      "|    value_loss           | 4.47e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.4      |\n",
      "|    ep_rew_mean          | 1.1e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 36        |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 611       |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.73e-05 |\n",
      "|    explained_variance   | 0.354     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.09e+04  |\n",
      "|    n_updates            | 1000      |\n",
      "|    policy_gradient_loss | -4.36e-10 |\n",
      "|    value_loss           | 4.94e+04  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 36       |\n",
      "|    ep_rew_mean          | 1.1e+03  |\n",
      "| time/                   |          |\n",
      "|    fps                  | 36       |\n",
      "|    iterations           | 12       |\n",
      "|    time_elapsed         | 677      |\n",
      "|    total_timesteps      | 24576    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00054 |\n",
      "|    explained_variance   | 0.27     |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 3.71e+04 |\n",
      "|    n_updates            | 1010     |\n",
      "|    policy_gradient_loss | 3.34e-07 |\n",
      "|    value_loss           | 5.36e+04 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.2      |\n",
      "|    ep_rew_mean          | 1.07e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 743       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000332 |\n",
      "|    explained_variance   | 0.369     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.43e+04  |\n",
      "|    n_updates            | 1020      |\n",
      "|    policy_gradient_loss | 4.83e-07  |\n",
      "|    value_loss           | 3.93e+04  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 34.6          |\n",
      "|    ep_rew_mean          | 1.09e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 35            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 805           |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6193447e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00166      |\n",
      "|    explained_variance   | 0.29          |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.96e+04      |\n",
      "|    n_updates            | 1030          |\n",
      "|    policy_gradient_loss | -2.5e-06      |\n",
      "|    value_loss           | 4.98e+04      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.2      |\n",
      "|    ep_rew_mean          | 1.1e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 874       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000314 |\n",
      "|    explained_variance   | 0.288     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.45e+04  |\n",
      "|    n_updates            | 1040      |\n",
      "|    policy_gradient_loss | 6.21e-07  |\n",
      "|    value_loss           | 5.97e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.8      |\n",
      "|    ep_rew_mean          | 1.06e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 934       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000276 |\n",
      "|    explained_variance   | 0.306     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.31e+04  |\n",
      "|    n_updates            | 1050      |\n",
      "|    policy_gradient_loss | 4.53e-07  |\n",
      "|    value_loss           | 4.75e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.9      |\n",
      "|    ep_rew_mean          | 1.07e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 997       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000104 |\n",
      "|    explained_variance   | 0.383     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.67e+04  |\n",
      "|    n_updates            | 1060      |\n",
      "|    policy_gradient_loss | 1.63e-07  |\n",
      "|    value_loss           | 3.8e+04   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36.4      |\n",
      "|    ep_rew_mean          | 1.09e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 1060      |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.21e-05 |\n",
      "|    explained_variance   | 0.328     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.24e+04  |\n",
      "|    n_updates            | 1070      |\n",
      "|    policy_gradient_loss | 1.63e-07  |\n",
      "|    value_loss           | 4.32e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36        |\n",
      "|    ep_rew_mean          | 1.09e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 1124      |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -7.27e-05 |\n",
      "|    explained_variance   | 0.426     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.17e+04  |\n",
      "|    n_updates            | 1080      |\n",
      "|    policy_gradient_loss | 1.54e-07  |\n",
      "|    value_loss           | 3.27e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.4      |\n",
      "|    ep_rew_mean          | 1.02e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 1184      |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.57e-05 |\n",
      "|    explained_variance   | 0.423     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.07e+04  |\n",
      "|    n_updates            | 1090      |\n",
      "|    policy_gradient_loss | 1.18e-07  |\n",
      "|    value_loss           | 4.62e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 35.2      |\n",
      "|    ep_rew_mean          | 1.07e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 1247      |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.04e-05 |\n",
      "|    explained_variance   | 0.552     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.12e+04  |\n",
      "|    n_updates            | 1100      |\n",
      "|    policy_gradient_loss | 3.19e-08  |\n",
      "|    value_loss           | 2.96e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 36        |\n",
      "|    ep_rew_mean          | 1.14e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 34        |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 1314      |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000404 |\n",
      "|    explained_variance   | 0.336     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.71e+04  |\n",
      "|    n_updates            | 1110      |\n",
      "|    policy_gradient_loss | -6.04e-07 |\n",
      "|    value_loss           | 4.16e+04  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.5         |\n",
      "|    ep_rew_mean          | 1.11e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 1381         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.246854e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00128     |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.63e+04     |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -1.84e-06    |\n",
      "|    value_loss           | 5.42e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.7         |\n",
      "|    ep_rew_mean          | 1.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 1440         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011564662 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000599    |\n",
      "|    explained_variance   | 0.318        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.47e+04     |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | 1.32e-05     |\n",
      "|    value_loss           | 5.1e+04      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 35            |\n",
      "|    ep_rew_mean          | 1.1e+03       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 34            |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 1503          |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1641532e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00166      |\n",
      "|    explained_variance   | 0.217         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 3.13e+04      |\n",
      "|    n_updates            | 1140          |\n",
      "|    policy_gradient_loss | 8.66e-07      |\n",
      "|    value_loss           | 5.33e+04      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 34.9      |\n",
      "|    ep_rew_mean          | 1.05e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 33        |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 1570      |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000187 |\n",
      "|    explained_variance   | 0.269     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.13e+04  |\n",
      "|    n_updates            | 1150      |\n",
      "|    policy_gradient_loss | 7.18e-07  |\n",
      "|    value_loss           | 5.18e+04  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.7         |\n",
      "|    ep_rew_mean          | 1.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 1634         |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.783498e-10 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00051     |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.18e+04     |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -4.53e-08    |\n",
      "|    value_loss           | 4.77e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 35.7          |\n",
      "|    ep_rew_mean          | 1.06e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 33            |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 1696          |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4386023e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00632      |\n",
      "|    explained_variance   | 0.259         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.88e+04      |\n",
      "|    n_updates            | 1170          |\n",
      "|    policy_gradient_loss | -3.17e-06     |\n",
      "|    value_loss           | 5.27e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 35.5          |\n",
      "|    ep_rew_mean          | 1.09e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 33            |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 1753          |\n",
      "|    total_timesteps      | 59392         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.3236955e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000969     |\n",
      "|    explained_variance   | 0.404         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 2.37e+04      |\n",
      "|    n_updates            | 1180          |\n",
      "|    policy_gradient_loss | 3.68e-06      |\n",
      "|    value_loss           | 3.76e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 34.8          |\n",
      "|    ep_rew_mean          | 1.09e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 33            |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 1807          |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.3050614e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00245      |\n",
      "|    explained_variance   | 0.295         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 2.32e+04      |\n",
      "|    n_updates            | 1190          |\n",
      "|    policy_gradient_loss | -3.55e-06     |\n",
      "|    value_loss           | 5.08e+04      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fd7de381fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = vizDoomGym(config='/Users/raghavsuri/Desktop/RLDOOM/Github/ViZDoom-master/scenarios/deadly_corridor4.cfg')\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=60000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd6b46ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor/PPO_22\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 15.6     |\n",
      "|    ep_rew_mean     | 298      |\n",
      "| time/              |          |\n",
      "|    fps             | 149      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 16           |\n",
      "|    ep_rew_mean          | 308          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029192064 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000133    |\n",
      "|    explained_variance   | -0.0546      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.26e+04     |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.000132    |\n",
      "|    value_loss           | 3.96e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 16.6      |\n",
      "|    ep_rew_mean          | 331       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 46        |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 132       |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.2e-07  |\n",
      "|    explained_variance   | 0.467     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.28e+04  |\n",
      "|    n_updates            | 1220      |\n",
      "|    policy_gradient_loss | -3.23e-09 |\n",
      "|    value_loss           | 3.07e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 15.8      |\n",
      "|    ep_rew_mean          | 305       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 42        |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 191       |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.84e-06 |\n",
      "|    explained_variance   | 0.512     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.85e+04  |\n",
      "|    n_updates            | 1230      |\n",
      "|    policy_gradient_loss | 3.7e-08   |\n",
      "|    value_loss           | 2.67e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 15.2      |\n",
      "|    ep_rew_mean          | 278       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 40        |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 251       |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.51e-05 |\n",
      "|    explained_variance   | 0.478     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.01e+04  |\n",
      "|    n_updates            | 1240      |\n",
      "|    policy_gradient_loss | 5.52e-08  |\n",
      "|    value_loss           | 3.06e+04  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 16       |\n",
      "|    ep_rew_mean          | 311      |\n",
      "| time/                   |          |\n",
      "|    fps                  | 39       |\n",
      "|    iterations           | 6        |\n",
      "|    time_elapsed         | 312      |\n",
      "|    total_timesteps      | 12288    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -3e-05   |\n",
      "|    explained_variance   | 0.463    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.63e+04 |\n",
      "|    n_updates            | 1250     |\n",
      "|    policy_gradient_loss | 8.13e-08 |\n",
      "|    value_loss           | 3.27e+04 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 15.8      |\n",
      "|    ep_rew_mean          | 306       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 374       |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.66e-05 |\n",
      "|    explained_variance   | 0.503     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.73e+04  |\n",
      "|    n_updates            | 1260      |\n",
      "|    policy_gradient_loss | 4.23e-08  |\n",
      "|    value_loss           | 3.04e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 17.3      |\n",
      "|    ep_rew_mean          | 353       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 441       |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000121 |\n",
      "|    explained_variance   | 0.51      |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.27e+04  |\n",
      "|    n_updates            | 1270      |\n",
      "|    policy_gradient_loss | 2.44e-07  |\n",
      "|    value_loss           | 2.81e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 16.6      |\n",
      "|    ep_rew_mean          | 316       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 36        |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 509       |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000199 |\n",
      "|    explained_variance   | 0.499     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 9.95e+03  |\n",
      "|    n_updates            | 1280      |\n",
      "|    policy_gradient_loss | 7.79e-07  |\n",
      "|    value_loss           | 2.88e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 15.6      |\n",
      "|    ep_rew_mean          | 287       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 576       |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000192 |\n",
      "|    explained_variance   | 0.511     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.72e+04  |\n",
      "|    n_updates            | 1290      |\n",
      "|    policy_gradient_loss | 1.22e-07  |\n",
      "|    value_loss           | 2.93e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 15.7      |\n",
      "|    ep_rew_mean          | 297       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 35        |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 642       |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000182 |\n",
      "|    explained_variance   | 0.497     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.53e+04  |\n",
      "|    n_updates            | 1300      |\n",
      "|    policy_gradient_loss | 3.05e-07  |\n",
      "|    value_loss           | 3.15e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 15.8         |\n",
      "|    ep_rew_mean          | 305          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 35           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 698          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.783498e-10 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000556    |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 6.35e+03     |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | 1.4e-06      |\n",
      "|    value_loss           | 2.65e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 15.6          |\n",
      "|    ep_rew_mean          | 294           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 35            |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 758           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.2386895e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000531     |\n",
      "|    explained_variance   | 0.508         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.63e+04      |\n",
      "|    n_updates            | 1320          |\n",
      "|    policy_gradient_loss | 1.01e-06      |\n",
      "|    value_loss           | 2.78e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 16.2          |\n",
      "|    ep_rew_mean          | 326           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 29            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 968           |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1641532e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000781     |\n",
      "|    explained_variance   | 0.549         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.5e+04       |\n",
      "|    n_updates            | 1330          |\n",
      "|    policy_gradient_loss | -4.08e-07     |\n",
      "|    value_loss           | 2.67e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 16.2         |\n",
      "|    ep_rew_mean          | 318          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 29           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1025         |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.783498e-10 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00105     |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.65e+04     |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | 1.02e-06     |\n",
      "|    value_loss           | 2.6e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 15.8         |\n",
      "|    ep_rew_mean          | 308          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 30           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1076         |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.895302e-10 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000384    |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.76e+04     |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | 6.33e-07     |\n",
      "|    value_loss           | 2.36e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 15.7          |\n",
      "|    ep_rew_mean          | 296           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 30            |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 1127          |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1304004e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00134      |\n",
      "|    explained_variance   | 0.562         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 5.01e+03      |\n",
      "|    n_updates            | 1360          |\n",
      "|    policy_gradient_loss | 9.46e-06      |\n",
      "|    value_loss           | 2.57e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 15.9          |\n",
      "|    ep_rew_mean          | 306           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 30            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 1197          |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4551915e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0012       |\n",
      "|    explained_variance   | 0.578         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 7.97e+03      |\n",
      "|    n_updates            | 1370          |\n",
      "|    policy_gradient_loss | 1.01e-06      |\n",
      "|    value_loss           | 2.54e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 16            |\n",
      "|    ep_rew_mean          | 307           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 31            |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 1251          |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6100467e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00212      |\n",
      "|    explained_variance   | 0.559         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1e+04         |\n",
      "|    n_updates            | 1380          |\n",
      "|    policy_gradient_loss | 1.5e-06       |\n",
      "|    value_loss           | 2.57e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 16.1         |\n",
      "|    ep_rew_mean          | 312          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 31           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 1303         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.476498e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0085      |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 8.45e+03     |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -1.8e-05     |\n",
      "|    value_loss           | 2.78e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 16.7          |\n",
      "|    ep_rew_mean          | 329           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 31            |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 1355          |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015443438 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0083       |\n",
      "|    explained_variance   | 0.494         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.58e+04      |\n",
      "|    n_updates            | 1400          |\n",
      "|    policy_gradient_loss | 8.43e-06      |\n",
      "|    value_loss           | 2.88e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 15.4         |\n",
      "|    ep_rew_mean          | 279          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 1407         |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.183377e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00332     |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 8.82e+03     |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | 2e-06        |\n",
      "|    value_loss           | 2.25e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 15.6          |\n",
      "|    ep_rew_mean          | 301           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 32            |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 1460          |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4738256e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00452      |\n",
      "|    explained_variance   | 0.49          |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 9.02e+03      |\n",
      "|    n_updates            | 1420          |\n",
      "|    policy_gradient_loss | 1.82e-05      |\n",
      "|    value_loss           | 2.92e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 15.9          |\n",
      "|    ep_rew_mean          | 309           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 32            |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 1516          |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3038516e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00192      |\n",
      "|    explained_variance   | 0.552         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.52e+04      |\n",
      "|    n_updates            | 1430          |\n",
      "|    policy_gradient_loss | 5.02e-06      |\n",
      "|    value_loss           | 2.38e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 15.1         |\n",
      "|    ep_rew_mean          | 274          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 1585         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.138603e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00145     |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+04     |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -4.9e-06     |\n",
      "|    value_loss           | 2.53e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 15.4         |\n",
      "|    ep_rew_mean          | 282          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 1650         |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.891749e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00221     |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+04     |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | 1.55e-06     |\n",
      "|    value_loss           | 2.89e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 16.1          |\n",
      "|    ep_rew_mean          | 313           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 31            |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 1731          |\n",
      "|    total_timesteps      | 55296         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1536835e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00157      |\n",
      "|    explained_variance   | 0.538         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.1e+04       |\n",
      "|    n_updates            | 1460          |\n",
      "|    policy_gradient_loss | -4.16e-06     |\n",
      "|    value_loss           | 2.7e+04       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 16.4          |\n",
      "|    ep_rew_mean          | 324           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 31            |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 1802          |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2759576e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00233      |\n",
      "|    explained_variance   | 0.479         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.38e+04      |\n",
      "|    n_updates            | 1470          |\n",
      "|    policy_gradient_loss | 1.39e-06      |\n",
      "|    value_loss           | 2.84e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 15.9          |\n",
      "|    ep_rew_mean          | 309           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 31            |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 1884          |\n",
      "|    total_timesteps      | 59392         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046354742 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00151      |\n",
      "|    explained_variance   | 0.553         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 7.45e+03      |\n",
      "|    n_updates            | 1480          |\n",
      "|    policy_gradient_loss | -0.000116     |\n",
      "|    value_loss           | 2.49e+04      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 15.5          |\n",
      "|    ep_rew_mean          | 293           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 32            |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 1919          |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5890691e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000634     |\n",
      "|    explained_variance   | 0.556         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 6.67e+03      |\n",
      "|    n_updates            | 1490          |\n",
      "|    policy_gradient_loss | -1.99e-06     |\n",
      "|    value_loss           | 2.57e+04      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fd7de381fd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = vizDoomGym(config='/Users/raghavsuri/Desktop/RLDOOM/Github/ViZDoom-master/scenarios/deadly_corridor5.cfg')\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=60000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c485df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c65856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10df4854",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('/Users/raghavsuri/Desktop/RLDOOM/train/train_corridor_5/best_model_300000.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bde9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = vizDoomGym(config='/Users/raghavsuri/Desktop/RLDOOM/Github/ViZDoom-master/scenarios/deadly_corridor5.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "439c9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = vizDoomGym(render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "abe7fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4aeb0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.526"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "79d7acfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[55],\n",
       "        [50],\n",
       "        [59],\n",
       "        ...,\n",
       "        [57],\n",
       "        [57],\n",
       "        [66]],\n",
       "\n",
       "       [[68],\n",
       "        [65],\n",
       "        [65],\n",
       "        ...,\n",
       "        [56],\n",
       "        [67],\n",
       "        [72]],\n",
       "\n",
       "       [[49],\n",
       "        [79],\n",
       "        [66],\n",
       "        ...,\n",
       "        [79],\n",
       "        [51],\n",
       "        [29]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[75],\n",
       "        [63],\n",
       "        [62],\n",
       "        ...,\n",
       "        [44],\n",
       "        [71],\n",
       "        [60]],\n",
       "\n",
       "       [[15],\n",
       "        [48],\n",
       "        [47],\n",
       "        ...,\n",
       "        [49],\n",
       "        [69],\n",
       "        [47]],\n",
       "\n",
       "       [[22],\n",
       "        [14],\n",
       "        [26],\n",
       "        ...,\n",
       "        [57],\n",
       "        [37],\n",
       "        [39]]], dtype=uint8)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea7dbe24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(1), None)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(obs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b7cd4667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(0), None)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "model.predict(obs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e8ec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward for episode 0 is 598.6637725830078\n",
      "Total reward for episode 1 is 1475.5499877929688\n",
      "Total reward for episode 2 is 1884.4003295898438\n",
      "Total reward for episode 3 is 1334.6001281738281\n"
     ]
    },
    {
     "ename": "ViZDoomUnexpectedExitException",
     "evalue": "Controlled ViZDoom instance exited unexpectedly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mViZDoomUnexpectedExitException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m      7\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[0;32m----> 8\u001b[0m     obs, reward, done,truncated ,info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.25\u001b[39m)\n\u001b[1;32m     10\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m, in \u001b[0;36mvizDoomGym.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action): \u001b[38;5;66;03m## Taking steps in env\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m     movement_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_state():\n",
      "\u001b[0;31mViZDoomUnexpectedExitException\u001b[0m: Controlled ViZDoom instance exited unexpectedly."
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "    obs = env.reset()\n",
    "    obs = obs[0]\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done,truncated ,info = env.step(action)\n",
    "        time.sleep(0.25)\n",
    "        total_reward += reward\n",
    "    print(\"Total reward for episode {} is {}\".format(episode, total_reward))\n",
    "    time.sleep(2)\n",
    "time.sleep(30)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d205cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
